{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classification de Koppen d'une liste de stations\n"
      ],
      "metadata": {
        "id": "kJQBNrMGsqD_"
      },
      "id": "kJQBNrMGsqD_"
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/nanopiero/tp_python_avance.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5P9xjnFw9vD",
        "outputId": "989f96bf-f839-445e-d459-adc488931f32"
      },
      "id": "U5P9xjnFw9vD",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'tp_python_avance' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls tp_python_avance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhPTN4dqxCMj",
        "outputId": "e8fa1c7e-e8d5-4d31-9716-0e046a50c8d4"
      },
      "id": "NhPTN4dqxCMj",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "koppen.ipynb  NORMALES_mens.data  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the .data file into a DataFrame\n",
        "# Replace 'your_file_path.data' with the actual path to your file\n",
        "file_path = 'tp_python_avance/NORMALES_mens.data'\n",
        "\n",
        "# Use the read_csv function, specifying the delimiter and decimal character\n",
        "df = pd.read_csv(file_path, delimiter=';', dtype={'POSTE': str}, decimal=',')\n",
        "\n",
        "# Display the first few rows of the DataFrame to check the data\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evDGVICaxgvf",
        "outputId": "5f87ba59-6bac-4263-df64-d74435060020"
      },
      "id": "evDGVICaxgvf",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      POSTE       NOM  ALT  DATE  RR_RRMOY  T_TMMOY\n",
            "0  01089001  AMBERIEU  250     1      84.9      3.2\n",
            "1  01089001  AMBERIEU  250     2      70.0      4.2\n",
            "2  01089001  AMBERIEU  250     3      75.0      8.0\n",
            "3  01089001  AMBERIEU  250     4      87.2     11.3\n",
            "4  01089001  AMBERIEU  250     5     106.4     15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Rename columns for clarity\n",
        "df.columns = ['POSTE', 'NOM', 'ALT', 'DATE', 'RR_RRMOY', 'T_TMMOY']\n",
        "\n",
        "# Create two new columns with month-specific names for precipitation and temperature\n",
        "df['RR'] = df['DATE'].apply(lambda x: f\"{int(x):02d}_RR\")  # Formats as '01_RR', '02_RR', etc.\n",
        "df['T'] = df['DATE'].apply(lambda x: f\"{int(x):02d}_T\")    # Formats as '01_T', '02_T', etc.\n",
        "\n",
        "# Pivot for precipitation and temperature, separately\n",
        "df_rr = df.pivot(index='NOM', columns='RR', values='RR_RRMOY')\n",
        "df_t = df.pivot(index='NOM', columns='T', values='T_TMMOY')\n",
        "\n",
        "# Merge the two pivoted DataFrames, keeping 'ALT' as a separate column\n",
        "df_alt = df[['NOM', 'POSTE', 'ALT']].drop_duplicates().set_index('NOM')\n",
        "result_df = pd.concat([df_alt, df_rr, df_t], axis=1).reset_index()\n",
        "\n",
        "result_df['hemisphere'] = \\\n",
        "    result_df.apply(department_and_hemisphere_from_dfrow, axis=1)\n",
        "\n",
        "# Display the reorganized DataFrame\n",
        "print(result_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gubP7Csdxoq6",
        "outputId": "74c3e940-a383-4439-c1ed-89f0853af6e0"
      },
      "id": "gubP7Csdxoq6",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              NOM     POSTE  ALT  01_RR  02_RR  03_RR  04_RR  05_RR  06_RR  \\\n",
            "0        AMBERIEU  01089001  250   84.9   70.0   75.0   87.2  106.4   88.8   \n",
            "1      ST QUENTIN  02320001   98   54.1   48.0   51.3   43.2   57.1   59.8   \n",
            "2  VICHY-CHARMEIL  03060001  249   48.1   37.5   43.5   68.5   88.4   72.7   \n",
            "3        ST AUBAN  04049001  458   48.2   35.9   44.7   64.8   63.9   53.5   \n",
            "4          EMBRUN  05046001  873   51.0   42.9   49.5   57.0   69.3   61.1   \n",
            "\n",
            "   07_RR  ...  05_T  06_T  07_T  08_T  09_T  10_T  11_T  12_T  13_T  \\\n",
            "0   86.0  ...  15.2  19.0  21.1  20.9  16.7  12.6   7.1   3.9  11.9   \n",
            "1   60.2  ...  13.4  16.2  18.4  18.4  15.2  11.4   6.9   4.1  10.8   \n",
            "2   75.7  ...  14.4  18.1  20.2  20.1  16.2  12.6   7.5   4.6  11.7   \n",
            "3   35.7  ...  16.0  20.2  23.1  22.8  18.4  14.0   8.7   5.2  13.4   \n",
            "4   49.2  ...  14.1  18.0  20.6  20.5  16.1  11.8   6.4   2.9  11.1   \n",
            "\n",
            "                  hemisphere  \n",
            "0  (01, Northern Hemisphere)  \n",
            "1  (02, Northern Hemisphere)  \n",
            "2  (03, Northern Hemisphere)  \n",
            "3  (04, Northern Hemisphere)  \n",
            "4  (05, Northern Hemisphere)  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def department_and_hemisphere_from_post_id(poste_id):\n",
        "    \"\"\"\n",
        "    Extracts the French department number from the POSTE ID and determines the hemisphere.\n",
        "\n",
        "    Args:\n",
        "        poste_id (str): The POSTE ID as a string.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (department_number (str), hemisphere (str))\n",
        "\n",
        "    Examples:\n",
        "    >>> department_and_hemisphere('01089001')\n",
        "    ('01', 'Northern Hemisphere')\n",
        "    >>> department_and_hemisphere('97320001')\n",
        "    ('973', 'Northern Hemisphere')\n",
        "    >>> department_and_hemisphere('98600001')\n",
        "    ('986', 'Southern Hemisphere')\n",
        "    >>> department_and_hemisphere('00100000')\n",
        "    ('00', 'Northern Hemisphere')\n",
        "    \"\"\"\n",
        "    # Extract the first 2 or 3 digits as the department number\n",
        "    department_number = poste_id[:3] if poste_id[:3] in ['971', '972', '973', '974', '976', '986', '987', '988'] else poste_id[:2]\n",
        "\n",
        "    # Determine the hemisphere (Northern for mainland France, Southern for French territories like '986')\n",
        "    southern_departments = {'986', '987', '988'}\n",
        "    hemisphere = 'Southern Hemisphere' if department_number in southern_departments else 'Northern Hemisphere'\n",
        "\n",
        "    return department_number, hemisphere\n",
        "\n",
        "\n",
        "def department_and_hemisphere_from_dfrow(row):\n",
        "    \"\"\"\n",
        "    wrapping of department_and_hemisphere\n",
        "    \"\"\"\n",
        "    poste_id = row['POSTE']\n",
        "    hemisphere = department_and_hemisphere_from_post_id(poste_id)\n",
        "    return hemisphere"
      ],
      "metadata": {
        "id": "wJ-o7peb9iaG"
      },
      "id": "wJ-o7peb9iaG",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to each row in result_df\n",
        "result_df['koppen_class'] = result_df.apply(koppen_classification, axis=1)\n",
        "\n",
        "# Display the updated DataFrame with Köppen class\n",
        "print(result_df[['NOM', 'ALT', 'koppen_class']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNdDSZmQx7-a",
        "outputId": "ad2d9cff-4cd1-4532-f4fd-e0675ff90a84"
      },
      "id": "QNdDSZmQx7-a",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              NOM  ALT koppen_class\n",
            "0        AMBERIEU  250          Cfb\n",
            "1      ST QUENTIN   98          Cfb\n",
            "2  VICHY-CHARMEIL  249          Cfb\n",
            "3        ST AUBAN  458          Cfa\n",
            "4          EMBRUN  873          Cfb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def koppen_classification(row):\n",
        "    \"\"\"\n",
        "    Determines the full Köppen classification for a given row in the DataFrame.\n",
        "\n",
        "    Args:\n",
        "        row (pd.Series): A row of the DataFrame with relevant climate data.\n",
        "\n",
        "    Returns:\n",
        "        str: The full Köppen classification or 'no_class' if it cannot be determined.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Extract data from the DataFrame row\n",
        "        alt = row['ALT']\n",
        "        monthly_precip = [row[f\"{str(month).zfill(2)}_RR\"] for month in range(1, 13)]\n",
        "        monthly_temp = [row[f\"{str(month).zfill(2)}_T\"] for month in range(1, 13)]\n",
        "        annual_precip = row.get(\"13_RR\", None)\n",
        "        annual_temp = row.get(\"13_T\", None)\n",
        "        hemisphere = row.get(\"Hemisphere\", None)  # If hemisphere info is available\n",
        "\n",
        "        # Initialize classification letters\n",
        "        class_letters = []\n",
        "\n",
        "        # Determine the first letter (main climate group)\n",
        "        try:\n",
        "            first_letter = koppen_class_first_letter(annual_temp, annual_precip, monthly_temp, monthly_precip)\n",
        "            class_letters.append(first_letter)\n",
        "        except Exception as e:\n",
        "            class_letters.append('no_class')\n",
        "            return 'no_class'  # Cannot proceed if the first letter fails\n",
        "\n",
        "        # Determine the second letter (precipitation pattern)\n",
        "        try:\n",
        "            class_letters.append(koppen_class_second_letter(first_letter, annual_precip, monthly_precip, hemisphere))\n",
        "        except Exception as e:\n",
        "            class_letters.append('no_class')\n",
        "\n",
        "        # Determine the third letter (temperature characteristics)\n",
        "        try:\n",
        "            class_letters.append(koppen_class_third_letter(first_letter, annual_temp, monthly_temp))\n",
        "        except Exception as e:\n",
        "            class_letters.append('no_class')\n",
        "\n",
        "        # Concatenate the letters to form the full classification\n",
        "        return ''.join([letter for letter in class_letters if letter != 'no_class']) or 'no_class'\n",
        "    except Exception as e:\n",
        "        return 'no_class'\n",
        "\n",
        "\n",
        "def koppen_class_first_letter(annual_temp, annual_precip, monthly_temp, monthly_precip):\n",
        "    \"\"\"\n",
        "    Determines the first letter of the Köppen classification.\n",
        "\n",
        "    Args:\n",
        "        annual_temp (float): Annual mean temperature.\n",
        "        annual_precip (float): Annual precipitation total.\n",
        "        monthly_temp (list): List of monthly mean temperatures.\n",
        "        monthly_precip (list): List of monthly precipitation totals.\n",
        "\n",
        "    Returns:\n",
        "        str: The first letter of the classification.\n",
        "    \"\"\"\n",
        "    if annual_temp > 18 and min(monthly_temp) > 18:\n",
        "        return 'A'  # Tropical\n",
        "    elif annual_precip < (annual_temp * 20 if annual_temp else 0):\n",
        "        return 'B'  # Arid\n",
        "    elif -3 <= min(monthly_temp) < 18 and max(monthly_temp) > 10:\n",
        "        return 'C'  # Temperate\n",
        "    elif min(monthly_temp) < -3 and max(monthly_temp) > 10:\n",
        "        return 'D'  # Continental\n",
        "    elif max(monthly_temp) < 10:\n",
        "        return 'E'  # Polar\n",
        "    else:\n",
        "        raise ValueError(\"Unable to determine first letter.\")\n",
        "\n",
        "\n",
        "def koppen_class_second_letter(first_letter, annual_precip, monthly_precip,\n",
        "                               hemisphere):\n",
        "    \"\"\"\n",
        "    Determines the second letter of the Köppen classification based on the first letter.\n",
        "\n",
        "    Args:\n",
        "        first_letter (str): The first letter of the classification.\n",
        "        annual_precip (float): Annual precipitation total.\n",
        "        monthly_precip (list): List of monthly precipitation totals.\n",
        "        hemisphere (str): 'Northern Hemisphere' or 'Southern Hemisphere'.\n",
        "\n",
        "    Returns:\n",
        "        str: The second letter of the classification.\n",
        "    \"\"\"\n",
        "    if first_letter == 'A':  # Tropical climates\n",
        "        P_dry = min(monthly_precip)\n",
        "        if P_dry >= 60:\n",
        "            return 'f'  # No dry season (rainforest)\n",
        "        elif P_dry < 60 and P_dry < (100 - annual_precip / 25):\n",
        "            return 'w'  # Dry winter (savanna)\n",
        "        elif P_dry < 60 and P_dry >= (100 - annual_precip / 25):\n",
        "            return 's'  # Dry summer (savanna)\n",
        "\n",
        "    elif first_letter in {'C', 'D'}:  # Temperate or Continental climates\n",
        "        if hemisphere == 'Northern Hemisphere':\n",
        "            P_wet = max(monthly_precip[11:] + monthly_precip[:2])  # Wettest winter month (Dec, Jan, Feb)\n",
        "            P_dry = min(monthly_precip[5:8])  # Driest summer month (Jun, Jul, Aug)\n",
        "        else:\n",
        "            P_wet = max(monthly_precip[5:8])  # Wettest winter month (Jun, Jul, Aug - Southern Hemisphere)\n",
        "            P_dry = min(monthly_precip[11:] + monthly_precip[:2])  # Driest summer month (Dec, Jan, Feb - Southern Hemisphere)\n",
        "\n",
        "        # Check for 'w' (dry winter)\n",
        "        if (P_dry < 40) and (P_dry < P_wet / 3):\n",
        "            return 'w'\n",
        "\n",
        "        # Check for 's' (dry summer)\n",
        "        if P_dry < 40 and P_dry < P_wet / 3:\n",
        "            return 's'\n",
        "\n",
        "        # If neither 'w' nor 's', it's 'f'\n",
        "        return 'f'\n",
        "\n",
        "    elif first_letter == 'B':  # Arid climates\n",
        "        return 'W' if annual_precip < 250 else 'S'  # Desert or Steppe\n",
        "\n",
        "    elif first_letter == 'E':  # Polar climates\n",
        "        return 'T' if max(monthly_precip) > 0 else 'F'  # Tundra or Ice Cap\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unable to determine second letter.\")\n",
        "\n",
        "\n",
        "\n",
        "def koppen_class_third_letter(first_letter, annual_temp, monthly_temp):\n",
        "    \"\"\"\n",
        "    Determines the third letter of the Köppen classification based on the first letter.\n",
        "\n",
        "    Args:\n",
        "        first_letter (str): The first letter of the classification.\n",
        "        annual_temp (float): Annual mean temperature.\n",
        "        monthly_temp (list): List of monthly mean temperatures.\n",
        "\n",
        "    Returns:\n",
        "        str: The third letter of the classification.\n",
        "    \"\"\"\n",
        "    if first_letter == 'A':  # Tropical climates don't have a third letter\n",
        "        return ''\n",
        "    elif first_letter == 'B':  # Arid climates\n",
        "        return 'h' if annual_temp > 18 else 'k'  # Hot or cold\n",
        "    elif first_letter in {'C', 'D'}:  # Temperate or Continental climates\n",
        "        if max(monthly_temp) > 22:\n",
        "            return 'a'  # Hot summer\n",
        "        elif 18 <= max(monthly_temp) <= 22:\n",
        "            return 'b'  # Warm summer\n",
        "        elif min(monthly_temp) > 0:\n",
        "            return 'c'  # Mild winter\n",
        "        else:\n",
        "            return 'd'  # Severe winter\n",
        "    elif first_letter == 'E':  # Polar climates\n",
        "        return ''  # Polar climates don't have a third letter\n",
        "    else:\n",
        "        raise ValueError(\"Unable to determine third letter.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "f3lEdSGQC3H0"
      },
      "id": "f3lEdSGQC3H0",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zvQPZ27WC4i0"
      },
      "id": "zvQPZ27WC4i0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the dictionary with lists of station names by koppen_class\n",
        "koppen_dict = result_df.groupby('koppen_class')['NOM'].apply(list).to_dict()\n",
        "\n",
        "# Display the dictionary\n",
        "print(koppen_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fvl7YdzyLe-",
        "outputId": "e1b5cb22-c15d-4836-a47b-05063b85cc83"
      },
      "id": "5fvl7YdzyLe-",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Af': ['LAMENTIN-AERO', 'MAOPOOPO', 'HIHIFO', 'BORA-BORA-MOTU-AERO', 'MANGAREVA', 'HIVA-OA', 'RAPA', 'TAKAROA', 'OUANAHAM'], 'As': ['LE RAIZET AERO', 'CAYENNE-MATOURY', 'SAINT GEORGES', 'MARIPASOULA', 'GILLOT-AEROPORT', 'FAAA'], 'Aw': ['ST-BARTHELEMY METEO', 'TROMELIN', 'PAMANDZI', 'NOUMEA', 'LA TONTOUTA'], 'Cfa': ['ST AUBAN', 'CANNES', 'NICE', 'LANAS SYN', 'CARCASSONNE', 'ISTRES', 'MARIGNANE', 'SALON DE PROVENCE', 'AJACCIO', 'CAP PERTUSATO', 'CALVI', 'ILE ROUSSE', 'FIGARI', 'BASTIA', 'SOLENZARA', 'MONTELIMAR', 'NIMES-COURBESSAC', 'NIMES-GARONS', 'TOULOUSE-BLAGNAC', 'MONTPELLIER-AEROPORT', 'BEZIERS-VIAS', 'SETE', 'PERPIGNAN', 'LYON-BRON', 'LYON-ST EXUPERY', 'ALBI', 'MONTAUBAN', 'LE LUC', 'HYERES', 'ILE DU LEVANT', 'AVIGNON', 'CARPENTRAS', 'ORANGE'], 'Cfb': ['AMBERIEU', 'ST QUENTIN', 'VICHY-CHARMEIL', 'EMBRUN', 'CHARLEVILLE-MEZ', 'ST GIRONS', 'TROYES-BARBEREY', 'MILLAU', 'RODEZ-AVEYRON', 'CAEN-CARPIQUET', 'AURILLAC', 'COGNAC', 'LA ROCHELLE-ILE DE RE', 'CHASSIRON', 'BOURGES', 'AVORD', 'BRIVE', 'DIJON-LONGVIC', 'BERGERAC', 'BESANCON', 'EVREUX-HUEST', 'CHARTRES', 'CHATEAUDUN', 'AUCH', 'BORDEAUX-MERIGNAC', 'CAZAUX', 'DINARD', 'RENNES-ST JACQUES', 'CHATEAUROUX  DEOLS', 'TOURS', 'GRENOBLE-ST GEOIRS', 'TAVAUX SA', 'BISCARROSSE', 'DAX', 'MONT-DE-MARSAN', 'ROMORANTIN', 'BLOIS', 'ST ETIENNE-BOUTHEON', 'NANTES-BOUGUENAIS', 'ST NAZAIRE-MONTOIR', 'ORLEANS', 'GOURDON', 'AGEN-LA GARENNE', 'BEAUCOUZE', 'REIMS-PRUNAY', 'LANGRES', 'ST-DIZIER', 'LAVAL-ETRONNIER', 'NANCY-OCHEY', 'NANCY-ESSEY', 'BELLE ILE-LE TALUT', 'LORIENT-LANN BIHOUE', 'AEROPORT METZ-NANCY-LORRAINE', 'NEVERS-MARZY', 'DUNKERQUE', 'LILLE-LESQUIN', 'CREIL', 'BEAUVAIS-TILLE', 'ALENCON', 'BOULOGNE-SEM', 'LE-TOUQUET', 'BIARRITZ-PAYS-BASQUE', 'SOCOA', 'PAU-UZEIN', 'TARBES-LOURDES-PYRENEES', 'STRASBOURG-ENTZHEIM', 'COLMAR-MEYENHEIM', 'BALE-MULHOUSE', 'LUXEUIL', 'MACON', 'ST YAN', 'LE MANS', 'BOURG ST MAURICE', 'CHAMBERY-AIX', 'MEYTHET', 'PARIS-MONTSOURIS', 'ROUEN-BOOS', 'OCTEVILLE', 'MELUN', 'TOUSSUS LE NOBLE', 'TRAPPES', 'NIORT', 'ABBEVILLE', 'MEAULTE', 'LA ROCHE SUR YON', 'POITIERS-BIARD', 'LIMOGES-BELLEGARDE', 'ORLY', 'PONTOISE - AERO', 'LE BOURGET', 'ROISSY'], 'Cfc': ['ST GATIEN DES B', 'LANNION_AERO', \"PLOUMANAC'H\", 'ST BRIEUC', 'BREST-GUIPAVAS', 'LANVEOC', 'OUESSANT-STIFF', 'QUIMPER', 'LANDIVISIAU', 'LE PUY-LOUDES', 'GONNEVILLE', 'DIEPPE', 'NOUVELLE AMSTERDAM'], 'Cfd': ['MONT AIGOUAL', 'ST-PIERRE'], 'Cwb': ['CLERMONT-FD'], 'EF': ['CROZET'], 'ET': ['KERGUELEN'], 'no_class': ['VILLAR ST PANCRACE', 'LEUCATE', 'BRIVE-SOUILLAC', 'CAP CORSE', 'ALISTRO', 'GUERET-ST LAURENT', 'PLOUDALMEZEAU', 'MENDE', 'MARCE', 'PTE DE LA HAGUE', 'VATRY-AERO', 'ILE DE GROIX', 'CAP BEAR', 'VILLACOUBLAY', 'L ILE D YEU', 'AUXERRE-PERRIGNY', 'DORANS', 'LA DESIRADE METEO', 'TRINITE-CARAVEL', 'SAINT LAURENT', 'GLORIEUSES', 'JUAN DE NOVA', 'EUROPA', 'HAO AERO', 'TAIARAPU-EST', 'KOUMAC']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "# Helper function to extract the town name\n",
        "import re\n",
        "\n",
        "def extract_town_name(station_name):\n",
        "    \"\"\"\n",
        "    Extracts the town name from a station name, handling special cases and cleaning it.\n",
        "\n",
        "    Args:\n",
        "        station_name (str): The original station name.\n",
        "\n",
        "    Returns:\n",
        "        str: The extracted and cleaned town name.\n",
        "\n",
        "    Examples:\n",
        "        >>> extract_town_name(\"L ILE D YEU\")\n",
        "        'ILE D YEU'\n",
        "        >>> extract_town_name(\"LYON-St EXUPERY-METEO\")\n",
        "        'LYON-ST EXUPERY'\n",
        "        >>> extract_town_name(\"MONT AIGUAL\")\n",
        "        'MONT AIGUAL'\n",
        "        >>> extract_town_name(\"PARIS-AERO\")\n",
        "        'PARIS'\n",
        "    \"\"\"\n",
        "    # Convert to uppercase for uniformity\n",
        "    station_name = station_name.upper()\n",
        "\n",
        "    # Remove \"METEO\", \"AERO\", \"AEROPORT\" and any dashes or spaces associated with them\n",
        "    station_name = re.sub(r\"(\\s?-?\\s?(METEO|AERO|AEROPORT)\\b)\", \"\", station_name)\n",
        "\n",
        "    # Handle specific cases\n",
        "    if station_name.startswith(\"L ILE\"):\n",
        "        station_name = station_name.replace(\"L ILE\", \"ILE\")\n",
        "\n",
        "    # Normalize \"Saint\" and \"St\" to \"ST\"\n",
        "    station_name = re.sub(r\"\\b(SAINT|ST)[\\-\\s\\.]*\", \"ST \", station_name)\n",
        "\n",
        "    # Preserve compound words like \"MONT AIGUAL\"\n",
        "    station_name = re.sub(r\"\\b(MONT|MT)\\b\", \"MONT\", station_name)\n",
        "\n",
        "    # Remove extra spaces and clean up\n",
        "    station_name = re.sub(r\"\\s{2,}\", \" \", station_name).strip()\n",
        "\n",
        "    return station_name\n",
        "\n",
        "\n",
        "# Step 1: Group station names by town\n",
        "town_groups = defaultdict(list)\n",
        "for idx, row in result_df.iterrows():\n",
        "    town_name = extract_town_name(row['NOM'])\n",
        "    town_groups[town_name].append((row['NOM'], row['koppen_class']))\n",
        "\n",
        "# Step 2: Check class consistency within each town group and build the new dictionary\n",
        "consistent_koppen_dict = defaultdict(list)\n",
        "\n",
        "for town, stations in town_groups.items():\n",
        "    # Extract classes, ignoring 'no_class'\n",
        "    classes = set([class_ for _, class_ in stations if class_ != 'no_class'])\n",
        "\n",
        "    if len(classes) == 1:\n",
        "        # All classes are consistent, add town to the unique class\n",
        "        consistent_class = classes.pop() if classes else 'no_class'\n",
        "        consistent_koppen_dict[consistent_class].append(town)\n",
        "    else:\n",
        "        # Inconsistent classes, add town to 'no_class'\n",
        "        consistent_koppen_dict['no_class'].append(town)\n",
        "\n",
        "# Display the resulting dictionary\n",
        "print(dict(consistent_koppen_dict))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4rRUcaiySqs",
        "outputId": "84a2b5fd-5325-41ea-ec45-3c861c3334a9"
      },
      "id": "e4rRUcaiySqs",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Cfb': ['AMBERIEU', 'ST QUENTIN', 'VICHY-CHARMEIL', 'EMBRUN', 'CHARLEVILLE-MEZ', 'ST GIRONS', 'TROYES-BARBEREY', 'MILLAU', 'RODEZ-AVEYRON', 'CAEN-CARPIQUET', 'AURILLAC', 'COGNAC', 'LA ROCHELLE-ILE DE RE', 'CHASSIRON', 'BOURGES', 'AVORD', 'BRIVE', 'DIJON-LONGVIC', 'BERGERAC', 'BESANCON', 'EVREUX-HUEST', 'CHARTRES', 'CHATEAUDUN', 'AUCH', 'BORDEAUX-MERIGNAC', 'CAZAUX', 'DINARD', 'RENNES-ST JACQUES', 'CHATEAUROUX DEOLS', 'TOURS', 'GRENOBLE-ST GEOIRS', 'TAVAUX SA', 'BISCARROSSE', 'DAX', 'MONT-DE-MARSAN', 'ROMORANTIN', 'BLOIS', 'ST ETIENNE-BOUTHEON', 'NANTES-BOUGUENAIS', 'ST NAZAIRE-MONTOIR', 'ORLEANS', 'GOURDON', 'AGEN-LA GARENNE', 'BEAUCOUZE', 'REIMS-PRUNAY', 'LANGRES', 'ST DIZIER', 'LAVAL-ETRONNIER', 'NANCY-OCHEY', 'NANCY-ESSEY', 'BELLE ILE-LE TALUT', 'LORIENT-LANN BIHOUE', 'METZ-NANCY-LORRAINE', 'NEVERS-MARZY', 'DUNKERQUE', 'LILLE-LESQUIN', 'CREIL', 'BEAUVAIS-TILLE', 'ALENCON', 'BOULOGNE-SEM', 'LE-TOUQUET', 'BIARRITZ-PAYS-BASQUE', 'SOCOA', 'PAU-UZEIN', 'TARBES-LOURDES-PYRENEES', 'ST RASBOURG-ENTZHEIM', 'COLMAR-MEYENHEIM', 'BALE-MULHOUSE', 'LUXEUIL', 'MACON', 'ST YAN', 'LE MANS', 'BOURG ST MAURICE', 'CHAMBERY-AIX', 'MEYTHET', 'PARIS-MONTSOURIS', 'ROUEN-BOOS', 'OCTEVILLE', 'MELUN', 'TOUSSUS LE NOBLE', 'TRAPPES', 'NIORT', 'ABBEVILLE', 'MEAULTE', 'LA ROCHE SUR YON', 'POITIERS-BIARD', 'LIMOGES-BELLEGARDE', 'ORLY', 'PONTOISE', 'LE BOURGET', 'ROISSY'], 'Cfa': ['ST AUBAN', 'CANNES', 'NICE', 'LANAS SYN', 'CARCASSONNE', 'ISTRES', 'MARIGNANE', 'SALON DE PROVENCE', 'AJACCIO', 'CAP PERTUSATO', 'CALVI', 'ILE ROUSSE', 'FIGARI', 'BASTIA', 'SOLENZARA', 'MONTELIMAR', 'NIMES-COURBESSAC', 'NIMES-GARONS', 'TOULOUSE-BLAGNAC', 'MONTPELLIER', 'BEZIERS-VIAS', 'SETE', 'PERPIGNAN', 'LYON-BRON', 'LYON-ST EXUPERY', 'ALBI', 'MONTAUBAN', 'LE LUC', 'HYERES', 'ILE DU LEVANT', 'AVIGNON', 'CARPENTRAS', 'ORANGE'], 'no_class': ['VILLAR ST PANCRACE', 'LEUCATE', 'BRIVE-SOUILLAC', 'CAP CORSE', 'ALISTRO', 'GUERET-ST LAURENT', 'PLOUDALMEZEAU', 'MENDE', 'MARCE', 'PTE DE LA HAGUE', 'VATRY', 'ILE DE GROIX', 'CAP BEAR', 'VILLACOUBLAY', 'ILE D YEU', 'AUXERRE-PERRIGNY', 'DORANS', 'LA DESIRADE', 'TRINITE-CARAVEL', 'ST LAURENT', 'GLORIEUSES', 'JUAN DE NOVA', 'EUROPA', 'HAO', 'TAIARAPU-EST', 'KOUMAC'], 'Cfc': ['ST GATIEN DES B', 'LANNION_', \"PLOUMANAC'H\", 'ST BRIEUC', 'BREST-GUIPAVAS', 'LANVEOC', 'OUESSANT-ST IFF', 'QUIMPER', 'LANDIVISIAU', 'LE PUY-LOUDES', 'GONNEVILLE', 'DIEPPE', 'NOUVELLE AMSTERDAM'], 'Cfd': ['MONT AIGOUAL', 'ST PIERRE'], 'Cwb': ['CLERMONT-FD'], 'As': ['LE RAIZET', 'CAYENNE-MATOURY', 'ST GEORGES', 'MARIPASOULA', 'GILLOT', 'FAAA'], 'Aw': ['ST BARTHELEMY', 'TROMELIN', 'PAMANDZI', 'NOUMEA', 'LA TONTOUTA'], 'Af': ['LAMENTIN', 'MAOPOOPO', 'HIHIFO', 'BORA-BORA-MOTU', 'MANGAREVA', 'HIVA-OA', 'RAPA', 'TAKAROA', 'OUANAHAM'], 'ET': ['KERGUELEN'], 'EF': ['CROZET']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_koppen_dict(nice_dict, max_words_per_line=5):\n",
        "    for koppen_class, towns in nice_dict.items():\n",
        "        print(f\"{koppen_class}:\")\n",
        "\n",
        "        # Split the list of towns into lines based on max_words_per_line\n",
        "        line = []\n",
        "        for i, town in enumerate(towns, 1):\n",
        "            line.append(town)\n",
        "            # Print and clear line every max_words_per_line words, or at the end\n",
        "            if i % max_words_per_line == 0 or i == len(towns):\n",
        "                print(\"    \" + \", \".join(line))\n",
        "                line = []  # Reset line for next batch\n",
        "        print()  # Blank line between classes\n",
        "\n",
        "# Display the dictionary with formatted output\n",
        "display_koppen_dict(consistent_koppen_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWB1Sg7GzAPS",
        "outputId": "fad1c299-bce7-4ff1-9e09-1ef48f5fb7cf"
      },
      "id": "qWB1Sg7GzAPS",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cfb:\n",
            "    AMBERIEU, ST QUENTIN, VICHY-CHARMEIL, EMBRUN, CHARLEVILLE-MEZ\n",
            "    ST GIRONS, TROYES-BARBEREY, MILLAU, RODEZ-AVEYRON, CAEN-CARPIQUET\n",
            "    AURILLAC, COGNAC, LA ROCHELLE-ILE DE RE, CHASSIRON, BOURGES\n",
            "    AVORD, BRIVE, DIJON-LONGVIC, BERGERAC, BESANCON\n",
            "    EVREUX-HUEST, CHARTRES, CHATEAUDUN, AUCH, BORDEAUX-MERIGNAC\n",
            "    CAZAUX, DINARD, RENNES-ST JACQUES, CHATEAUROUX DEOLS, TOURS\n",
            "    GRENOBLE-ST GEOIRS, TAVAUX SA, BISCARROSSE, DAX, MONT-DE-MARSAN\n",
            "    ROMORANTIN, BLOIS, ST ETIENNE-BOUTHEON, NANTES-BOUGUENAIS, ST NAZAIRE-MONTOIR\n",
            "    ORLEANS, GOURDON, AGEN-LA GARENNE, BEAUCOUZE, REIMS-PRUNAY\n",
            "    LANGRES, ST DIZIER, LAVAL-ETRONNIER, NANCY-OCHEY, NANCY-ESSEY\n",
            "    BELLE ILE-LE TALUT, LORIENT-LANN BIHOUE, METZ-NANCY-LORRAINE, NEVERS-MARZY, DUNKERQUE\n",
            "    LILLE-LESQUIN, CREIL, BEAUVAIS-TILLE, ALENCON, BOULOGNE-SEM\n",
            "    LE-TOUQUET, BIARRITZ-PAYS-BASQUE, SOCOA, PAU-UZEIN, TARBES-LOURDES-PYRENEES\n",
            "    ST RASBOURG-ENTZHEIM, COLMAR-MEYENHEIM, BALE-MULHOUSE, LUXEUIL, MACON\n",
            "    ST YAN, LE MANS, BOURG ST MAURICE, CHAMBERY-AIX, MEYTHET\n",
            "    PARIS-MONTSOURIS, ROUEN-BOOS, OCTEVILLE, MELUN, TOUSSUS LE NOBLE\n",
            "    TRAPPES, NIORT, ABBEVILLE, MEAULTE, LA ROCHE SUR YON\n",
            "    POITIERS-BIARD, LIMOGES-BELLEGARDE, ORLY, PONTOISE, LE BOURGET\n",
            "    ROISSY\n",
            "\n",
            "Cfa:\n",
            "    ST AUBAN, CANNES, NICE, LANAS SYN, CARCASSONNE\n",
            "    ISTRES, MARIGNANE, SALON DE PROVENCE, AJACCIO, CAP PERTUSATO\n",
            "    CALVI, ILE ROUSSE, FIGARI, BASTIA, SOLENZARA\n",
            "    MONTELIMAR, NIMES-COURBESSAC, NIMES-GARONS, TOULOUSE-BLAGNAC, MONTPELLIER\n",
            "    BEZIERS-VIAS, SETE, PERPIGNAN, LYON-BRON, LYON-ST EXUPERY\n",
            "    ALBI, MONTAUBAN, LE LUC, HYERES, ILE DU LEVANT\n",
            "    AVIGNON, CARPENTRAS, ORANGE\n",
            "\n",
            "no_class:\n",
            "    VILLAR ST PANCRACE, LEUCATE, BRIVE-SOUILLAC, CAP CORSE, ALISTRO\n",
            "    GUERET-ST LAURENT, PLOUDALMEZEAU, MENDE, MARCE, PTE DE LA HAGUE\n",
            "    VATRY, ILE DE GROIX, CAP BEAR, VILLACOUBLAY, ILE D YEU\n",
            "    AUXERRE-PERRIGNY, DORANS, LA DESIRADE, TRINITE-CARAVEL, ST LAURENT\n",
            "    GLORIEUSES, JUAN DE NOVA, EUROPA, HAO, TAIARAPU-EST\n",
            "    KOUMAC\n",
            "\n",
            "Cfc:\n",
            "    ST GATIEN DES B, LANNION_, PLOUMANAC'H, ST BRIEUC, BREST-GUIPAVAS\n",
            "    LANVEOC, OUESSANT-ST IFF, QUIMPER, LANDIVISIAU, LE PUY-LOUDES\n",
            "    GONNEVILLE, DIEPPE, NOUVELLE AMSTERDAM\n",
            "\n",
            "Cfd:\n",
            "    MONT AIGOUAL, ST PIERRE\n",
            "\n",
            "Cwb:\n",
            "    CLERMONT-FD\n",
            "\n",
            "As:\n",
            "    LE RAIZET, CAYENNE-MATOURY, ST GEORGES, MARIPASOULA, GILLOT\n",
            "    FAAA\n",
            "\n",
            "Aw:\n",
            "    ST BARTHELEMY, TROMELIN, PAMANDZI, NOUMEA, LA TONTOUTA\n",
            "\n",
            "Af:\n",
            "    LAMENTIN, MAOPOOPO, HIHIFO, BORA-BORA-MOTU, MANGAREVA\n",
            "    HIVA-OA, RAPA, TAKAROA, OUANAHAM\n",
            "\n",
            "ET:\n",
            "    KERGUELEN\n",
            "\n",
            "EF:\n",
            "    CROZET\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N8akLAa9zAzf"
      },
      "id": "N8akLAa9zAzf",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}